## Solutions

### Exercise 1 {-}

Using a little bit of algebra, use (4.2) to achieve (4.3). In other words, the logistic function representation and logit representation for the logistic regression model are equivalent.

**Answer:** 

Equations (4.2) and (4.3) are the following:

$$ 
(4.2) \quad p(X) = \frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}\qquad\qquad
(4.3)  \quad  \frac {p(X)} {1 - p(X)} =e^{\beta_0 + \beta_1 X}
$$


Derivations:

$$
\begin{align*}\frac {p(X)} {1 - p(X)} 
&= \frac {\frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}{1 - \frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}} 
= \frac {\frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}{\frac {1 + e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}} - \frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}} 
= \frac {\frac {e^{\beta_0 + \beta_1 X}} {1 + e^{\beta_0 + \beta_1 X}}}{\frac {1} {1 + e^{\beta_0 + \beta_1 X}}} 
= e^{\beta_0 + \beta_1 X}
\end{align*}
$$

### Exercise 6 {-}

Suppose we collect data for a group of students in a statistics class with variables $X_1=$`hours studied`, $X_2 =$ `undergrad GPA`, and $Y =$ `receive an A`. We fit a logistic regression and produce estimated coefficients:

$$\hat{\beta}_0 = -6, \quad \hat{\beta}_1 = 0.05, \quad \hat{\beta}_2 = 1.$$

**6 a)** Estimate the probability that a student who studies for $40$ h and has an `undergrad GPA` of $3.5$ gets an `A` in the class.

**Answer:**

Remember from the previous exercise that:

$$ 
p(X) = \frac {\exp(\beta_0 + \beta_1 X_1 + \beta_2 X_2)}
             {1 + \exp(\beta_0 + \beta_1 X_1 + \beta_2 X_2)}
\\
$$

Thus, the probability of $Y=1$ given $X=[x_1,x_2]$ with $x_1 =40$ (hours) and $x_2=3.5$ (GPA) yields:

$$ 
p(X) =  \frac {\exp(-6 + 0.05\cdot 40 + 3.5)} {1 + \exp(-6 + 0.05\cdot 40 + 3.5)} = \frac {\exp(-0.5)} {1 + \exp(-0.5)} = 37.75\%
$$


**6 b)** How many hours would the student in part (a) need to study to have a $50\%$ chance of getting an `A` in the class?

**Answer:**

Finding $x_1$, where $X = [x_1, 3.5]$, such that $p(X) = 0.5$ yields:

$$
\begin{align*}
0.50 &= \frac {\exp(-6 + 0.05 x_1 + 3.5)} {1 + \exp(-6 + 0.05 x_1 + 3.5)} \\
\Leftrightarrow 0.50 (1 + \exp(-2.5 + 0.05\,x_1)) &= \exp(-2.5 + 0.05\,x_1)\\
\Leftrightarrow 0.50 + 0.50 \exp(-2.5 + 0.05\,x_1)) &= \exp(-2.5 + 0.05\,x_1)\\
\Leftrightarrow 0.50 &= 0.50 \exp(-2.5 + 0.05\,x_1)\\
\Leftrightarrow \log(1) &= -2.5 + 0.05\,x_1 \\
\Leftrightarrow x_1 &= 2.5 / 0.05 = 50 
\end{align*}
$$


### Exercise 13 {-}

This question should be answered using the `Weekly` data set, which is part of the `ISLR` package. This data is similar in nature to the Smarket data from this chapterâ€™s lab, except that it contains $1,089$ weekly returns for $21$ years, from the beginning of $1990$ to the end of $2010$.

**13 a)** Produce some numerical and graphical summaries of the Weekly data. Do there appear to be any patterns?


**Answer:**


```{r}
# You may need to install first the following R-packages:
# install.packages("ISLR2")
# install.packages("MASS")
# install.packages("class")
# install.packages("e1071") # naiveBayes()

# Load the packages you need
library("ISLR2")

# Eliminates the need of referring to a variable like Weekly$variable
attach(Weekly) 

# Use summary function to produce a numerical summary for each variable
summary(Weekly)
```

```{r}
# Use cor function to produce a table of correlations for all variables 
# (excluding the non-numerical variable 'Direction')
round(cor(Weekly[,-9]), 2)
```

```{r}
# Use pairs function to produce pairwise scatter plots
pairs(Weekly)
```

Yes, it appears that `Year` and `Volume` have a strong, positive, but non-linear relationship.

**13 b)** Use the full data set to perform a logistic regression with `Direction` as the response and the five `Lag` variables plus `Volume` as predictors. Use the `summary()` function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?

**Answer:** 

```{r}
# Estimate a generalized linear regression model where the third input family is a description of the error distribution 
# and link function to be used in the model, supplied as the result of a call to a family function - here use binomial.
# Why binomial? Because our independent variable Direction takes two values.

glm.fit <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
              data=Weekly,
              family=binomial)

# Use summary function to print the results
summary(glm.fit)
```

**Conclusion:** The predictor `Lag2` appears to have some statistical significance with a $p$-value smaller than $3\%$.

**13 c)** Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.

**Answer:** 

```{r}
# Use predict function on results of previous regression in 10 b)
glm.probs <-  predict(glm.fit, type="response")

# Create a vector containing the string "Down" 
glm.pred <- rep("Down", times = length(glm.probs))

# Substitute "Down" for "Up", whenever the estimated probability is above 0.5
glm.pred[glm.probs > 0.5] <- "Up"

# Construct a summary table with the predictions against 
# the actual 'Direction'-values
table(glm.pred, Direction)
```


**Conclusions:**

- Percentage of correct predictions: $(54+557)/(54+557+48+430) = 56.1\%$ 

- During weeks when the market goes `Up`, the logistic regression is right about $557/(557+48) = 92.1\%$ of the time.

- During weeks when the market goes `Down`, the logistic regression is right about $54/(430+54) = 11.2\%$ of the time.


**13 d)** Now fit the logistic regression model using a training data period from $1990$ to $2008$, with `Lag2` as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from $2009$ and $2010$).

**Answer:** 

```{r}
# generate condition for our training data
train = (Year < 2009)

# create data frame for the Weekly data from 2009 and 2010 
# (usage of ! to define the "opposite")
Weekly.0910 <- Weekly[!train,]

# run regression on the training data subset
glm.fit <- glm(Direction ~ Lag2,
              data   = Weekly,
              family = binomial,
              subset = train)

# create data frame
glm.probs <- predict(glm.fit, Weekly.0910, type="response")

# fill with our predictions
glm.pred <- rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] <- "Up"

# construct confusion table using only the test data
Direction.0910 <- Direction[!train]
table(glm.pred, Direction.0910)

# compute the test error rate
mean(glm.pred != Direction.0910)
```

**13 e)** Repeat (d) using LDA.

**Answer:** 

```{r}
#call the packages you need
library("MASS")

# same approach as before but now using LDA method
lda.fit  <- lda(Direction ~ Lag2, data=Weekly, subset=train)
lda.pred <- predict(lda.fit, Weekly.0910)

# confusion table using only the test data
table(lda.pred$class, Direction.0910)

# compute the test error rate
mean(lda.pred$class != Direction.0910)
```

**13 f)** Repeat (d) using QDA.

**Answer:** 

```{r}
# same approach as before but now using QDA method
qda.fit   <- qda(Direction~Lag2, data=Weekly, subset=train)
qda.class <- predict(qda.fit, Weekly.0910)$class

# confusion table using only the test data
table(qda.class, Direction.0910)

# compute the test error rate
mean(qda.class != Direction.0910)
```

**13 g)** Repeat (d) using KNN with K = 1.

**Answer:** 

```{r}
# call the package you need
library("class")

# same approach as before but now using KNN method with K=1
train.X         <- as.matrix(Lag2[train])
test.X          <- as.matrix(Lag2[!train])
train.Direction <- Direction[train]

# Note: If several observations are tied as nearest neighbors, 
# then R will randomly break the tie. 
# Setting a common seed guarantees that we get the same results 
set.seed(1)

# Caution: KNN prediction uses a different function
knn.pred <- knn(train.X, test.X, train.Direction, k=1)

# confusion table using only the test data
table(knn.pred, Direction.0910)

# compute the test error rate
mean(knn.pred != Direction.0910)
```


**13 h)** Repeat (d) using naive Bayes. 

**Answer:** 

```{r}
library(e1071)
nb.fit  <- naiveBayes(Direction ~ Lag2, data=Weekly, subset=train)
nb.pred <- predict(nb.fit, Weekly.0910)

# confusion table using only the test data
table(nb.pred, Direction.0910)

# compute the test error rate
mean(nb.pred != Direction.0910)
```


**13 i)** Which of these methods appears to provide the best results on this data?

**Answer:** 

Logistic regression and LDA have the smallest test error rates.

**13 j)** Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for $K$ in the KNN classifier.

**Answer:** 

```{r}
# Logistic regression with Lag2:Lag1
glm.fit   <- glm(Direction~Lag2:Lag1, data=Weekly, family=binomial, subset=train)
glm.probs <- predict(glm.fit, Weekly.0910, type="response")
glm.pred  <- rep("Down", length(glm.probs))
glm.pred[glm.probs>.5] <- "Up"
Direction.0910 <- Direction[!train]
table(glm.pred, Direction.0910)
mean(glm.pred == Direction.0910)
```

```{r}
# LDA with Lag2 interaction with Lag1
lda.fit  <- lda(Direction ~ Lag2:Lag1, data=Weekly, subset=train)
lda.pred <- predict(lda.fit, Weekly.0910)
mean(lda.pred$class == Direction.0910)
```

```{r}
# QDA with sqrt(abs(Lag2))
qda.fit   <- qda(Direction~Lag2+sqrt(abs(Lag2)), data=Weekly, subset=train)
qda.class <- predict(qda.fit, Weekly.0910)$class
table(qda.class, Direction.0910)
mean(qda.class == Direction.0910)
```

```{r}
# KNN k =10, as before KNN uses a different command
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Direction, k=10)
table(knn.pred, Direction.0910)
mean(knn.pred == Direction.0910)
```

```{r}
# KNN k = 100
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Direction, k=100)
table(knn.pred, Direction.0910)
mean(knn.pred == Direction.0910)
```

**Conclusion:** Out of these experiement, the original LDA and logistic regression have better performance in terms of test error rate.



### Exercise 15 {-}

This problem involves writing functions.

**15 a)** Write a function, `Power()`, that prints out the result of raising 2 to the 3rd power. In other words, your function should compute $2^3$ and print out the results. Hint: Recall that `x^a` raises `x` to the power `a`. Use the `print()` function to output the result.

**Answer:** 

```{r}
Power <- function() {
  2^3
}
Power()
```

**15 b)** Create a new function, `Power2()`, that allows you to pass any two numbers, `x` and `a`, and prints out the value of `x^a`. You can do this by beginning your function with the line `Power2 <- function (x,a){`. You should be able to call your function by entering, for instance, `Power2 (3,8)` on the command line. This should output the value of $38$, namely, $6,561$.

**Answer:** 

```{r}
Power2 <- function(x, a) {
  x^a
}
Power2(3,8)
```

**15 c)** Using the `Power2()` function that you just wrote, compute $10^3$, $8^{17}$, and $131^3$.

**Answer:** 

```{r}
Power2(10, 3)
Power2(8, 17)
Power2(131, 3)
```

**15 d)** Now create a new function, `Power3()`, that actually returns the result `x^a` as an R object, rather than simply printing it to the screen. That is, if you store the value `x^a` in an object called result within your function, then you can simply `return()` this result, using the following line: `return(result)`. This should be the last line in your function, before the `}` symbol.

**Answer:** 

```{r}
Power3 <- function(x, a) {
  result <- x^a
  return(result)
}
```

**15 e)** Now using the `Power3()` function, create a plot of f(x) = $x^2$. The x-axis should display a range of integers from 1 to 10, and the y-axis should display $x^2$. Label the axes appropriately, and use an appropriate title for the figure. Consider displaying either the x-axis, the y-axis, or both on the log-scale. You can do this by using `log="x"`, `log="y"`, or `log="xy"` as arguments to the `plot()` function.

**Answer:** 

```{r}
x <- 1:10
par(mfrow=c(1,3))# graph parameters
plot(x, Power3(x, 2),  log="x", ylab=expression(x^2), xlab=expression(x),
     main="log-transformed\nx-axis")
plot(x, Power3(x, 2),  log="y", ylab=expression(x^2), xlab=expression(x),
     main="log-transformed\ny-axis")
plot(x, Power3(x, 2),  log="xy", ylab=expression(x^2), xlab=expression(x),
     main="log-transformed\nx and y-axis")
par(mfrow=c(1,1))# reset graphic parameters
```

**15 f)** Create a function, `PlotPower()`, that allows you to create a plot of `x` against `x^a` for a fixed `a` and for a range of values of `x`. For instance, if you call `PlotPower (1:10 ,3)` then a plot should be created with an x-axis taking on values $1, 2, \dots , 10$, and a y-axis taking on values $1^3$, $2^3$, . . . , $10^3$.

**Answer:** 

```{r}
PlotPower = function(x, a) {
  ylab_text <- bquote('x'^.(a)) # write y-axis label
  plot(x, Power3(x, a),
       ylab = ylab_text)
}
PlotPower(1:10, 3)
```

### Exercise 16 {-}

Using the `Boston` data set, fit classification models in order to predict whether a given suburb has a crime rate above or below the median. Explore logistic regression, LDA, and KNN models using various subsets of the predictors. Describe your findings.

**Answer:** 

```{r}
summary(Boston)
attach(Boston)

crime01 <- rep(0, length(crim))
crime01[crim > median(crim)] = 1

Boston <- data.frame(Boston, crime01)

train <- 1:(dim(Boston)[1]/2)
test  <- (dim(Boston)[1]/2+1):dim(Boston)[1]

Boston.train <- Boston[train,]
Boston.test  <- Boston[test,]
crime01.test <- crime01[test]
```

```{r}
# logistic regression
glm.fit <- glm(crime01~.-crime01-crim, 
              data   = Boston, 
              family = binomial, 
              subset = train)

glm.probs <- predict(glm.fit, Boston.test, type="response")

glm.pred = rep(0, length(glm.probs))
glm.pred[glm.probs > 0.5] = 1

mean(glm.pred != crime01.test)
```

**Conclusion:** This logistic regression has a test error rate of $18.2\%$.

```{r}
glm.fit = glm(crime01~.-crime01-crim-chas-tax, 
              data=Boston, family=binomial, subset=train)
glm.probs = predict(glm.fit, Boston.test, type="response")
glm.pred = rep(0, length(glm.probs))
glm.pred[glm.probs > 0.5] = 1
mean(glm.pred != crime01.test)
```

**Conclusion:** This logistic regression has a test error rate of $18.6\%$.


```{r}
# LDA
lda.fit = lda(crime01~.-crime01-crim, data=Boston, subset=train)
lda.pred = predict(lda.fit, Boston.test)
mean(lda.pred$class != crime01.test)
```

**Conclusion:** This LDA has a test error rate of $13.4\%$.


```{r}
lda.fit = lda(crime01~.-crime01-crim-chas-tax, data=Boston, subset=train)
lda.pred = predict(lda.fit, Boston.test)
mean(lda.pred$class != crime01.test)
```

**Conclusion:** This LDA has a test error rate of $12.3\%$.


```{r}
lda.fit = lda(crime01~.-crime01-crim-chas-tax-lstat-indus-age,
              data=Boston, subset=train)
lda.pred = predict(lda.fit, Boston.test)
mean(lda.pred$class != crime01.test)
```

**Conclusion:** This LDA has a test error rate of $11.9\%$.

```{r}
# KNN
library(class)
train.X = cbind(zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black,
                lstat, medv)[train,]
test.X = cbind(zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black,
                lstat, medv)[test,]
train.crime01 = crime01[train]

set.seed(1)
# KNN(k=1)
knn.pred = knn(train.X, test.X, train.crime01, k=1)
mean(knn.pred != crime01.test)
```

**Conclusion:** This KNN prediction has a test error rate of $45.8\%$.

```{r}
# KNN(k=10)
set.seed(1)
knn.pred = knn(train.X, test.X, train.crime01, k=10)
mean(knn.pred != crime01.test)
```

**Conclusion:** This KNN prediction has a test error rate of $11.1\%$.

```{r}
# KNN(k=100)
set.seed(1)
knn.pred = knn(train.X, test.X, train.crime01, k=100)
mean(knn.pred != crime01.test)
```

**Conclusion:** This KNN prediction has a test error rate of $48.6\%$.


**Overall conclusion:** In general, the best models are the ones with the smaller test error rates. 
In our case, this means that the smallest LDA-model and the KNN prediction with `K=10` are the best prediction models.

